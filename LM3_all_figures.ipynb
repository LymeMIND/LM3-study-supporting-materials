{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3fd876c",
   "metadata": {},
   "source": [
    "## <u>Online interactive Jupyter notebook as a supplement for:</u>\n",
    "\n",
    "# Biomarker Set Identification for Post-Treatment Lyme Disease\n",
    "\n",
    "**Daniel J.B. Clarke<sup>1</sup>, Alison W. Rebman<sup>2</sup>, Jinshui Fan<sup>2</sup>, Mark J. Soloski<sup>2</sup>, John N. Aucott<sup>2,\\*</sup>, Avi Maâ€™ayan<sup>1,\\*</sup>**\n",
    "\n",
    "<sup>1</sup> Department of Pharmacological Sciences; Mount Sinai Center for Bioinformatics; Icahn School of Medicine at Mount Sinai, One Gustave L. Levy Place, Box 1603, New York, NY 10029, USA\n",
    "\n",
    "<sup>2</sup> Lyme Disease Research Center, Division of Rheumatology, Department of Medicine, Johns Hopkins University School of Medicine, Baltimore, MD, United States\n",
    "\n",
    "\\* To whom correspondence should be addressed: jaucott2@jhmi.edu; avi.maayan@mssm.edu \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18769e3",
   "metadata": {},
   "source": [
    "### Install dependencies\n",
    "\n",
    "```bash\n",
    "cat > requirements.txt << EOF\n",
    "imbalanced-learn\n",
    "maayanlab_bioinformatics@git+https://github.com/MaayanLab/maayanlab-bioinformatics.git@v0.5.1\n",
    "matplotlib_venn\n",
    "matplotlib\n",
    "numpy\n",
    "pandas\n",
    "plotly\n",
    "requests\n",
    "seaborn\n",
    "sklearn\n",
    "supervenn\n",
    "EOF\n",
    "\n",
    "pip3 install -r requirements.txt\n",
    "\n",
    "cat > setup.R << EOF\n",
    "install.packages(\"R.utils\")\n",
    "install.packages(\"RCurl\")\n",
    "\n",
    "if (!requireNamespace(\"BiocManager\", quietly = TRUE))\n",
    "    install.packages(\"BiocManager\")\n",
    "\n",
    "BiocManager::install(\"DESeq2\")\n",
    "BiocManager::install(\"limma\")\n",
    "BiocManager::install(\"statmod\")\n",
    "BiocManager::install(\"edgeR\")\n",
    "EOF\n",
    "\n",
    "Rscript setup.R\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bb0934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "from matplotlib_venn import venn3\n",
    "from supervenn import supervenn\n",
    "from collections import OrderedDict\n",
    "from IPython.display import display, Markdown\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, permutation_test_score, train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import plot_roc_curve, plot_precision_recall_curve, plot_confusion_matrix, roc_curve, precision_recall_curve, confusion_matrix, auc, roc_auc_score, average_precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from maayanlab_bioinformatics.harmonization import ncbi_genes_lookup\n",
    "from maayanlab_bioinformatics.harmonization import transcripts_to_genes\n",
    "from maayanlab_bioinformatics.harmonization import ncbi_genes_lookup\n",
    "from maayanlab_bioinformatics.normalization import zscore_normalize, quantile_normalize, log2_normalize, filter_by_expr, filter_by_var\n",
    "from maayanlab_bioinformatics.dge import limma_voom_differential_expression\n",
    "from maayanlab_bioinformatics.api import EnrichrUserList\n",
    "from maayanlab_bioinformatics.parse import gmt_read_dict\n",
    "\n",
    "_lookup = ncbi_genes_lookup()\n",
    "lookup = lambda gene: _lookup(gene, gene).upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c569fc48-0683-423f-b238-b2021e91e3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "data = pathlib.Path('data')\n",
    "figures = pathlib.Path('figures')\n",
    "figures.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba18d41",
   "metadata": {},
   "source": [
    "## LM2/LM3 Clinical Metadata Preparation\n",
    "\n",
    "Construct unified metadata dataframes for LM2 & LM3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58c6a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_desc(df, df_desc):\n",
    "    ''' Ensure types match descriptors '''\n",
    "    for column, kind in df_desc.items():\n",
    "        if kind == 'categorical':\n",
    "            df[column] = df[column].astype(float).dropna().astype(str)\n",
    "        elif kind in {'label', 'timepoint'}:\n",
    "            df[column] = df[column].dropna().astype(str)\n",
    "        elif kind == 'continuous':\n",
    "            df[column] = df[column].astype(float)\n",
    "    return df\n",
    "\n",
    "df_lm2_clinical = pd.read_csv(\n",
    "    data / 'LM_Slice2_Slice3_data/LM2_Clinical_Entrez.csv', index_col=0\n",
    ")\n",
    "df_lm2_clinical_desc = {\n",
    "    'orig_id': 'label',\n",
    "    'time_point': 'label',\n",
    "    'nebnext_index_read': 'label',\n",
    "    'date': 'label',\n",
    "    'batch': 'categorical',\n",
    "    'pid': 'id',\n",
    "    'visit': 'timepoint',\n",
    "    'season_yr': 'categorical',\n",
    "    'gender': 'categorical',\n",
    "    'age': 'continuous',\n",
    "    'hispa_dg': 'categorical',\n",
    "    'race1_dg': 'categorical',\n",
    "    'race2_dg': 'categorical',\n",
    "    'hrsanti': 'categorical',\n",
    "    'a1msd_fa': 'categorical',\n",
    "    'durat': 'continuous',\n",
    "    'durat_tx': 'continuous',\n",
    "    'dissem': 'categorical',\n",
    "    'rashsize': 'continuous',\n",
    "    'elres_l2': 'categorical',\n",
    "    'wbmto_l2': 'continuous',\n",
    "    'wbgto_l2': 'continuous',\n",
    "    'sero1': 'categorical',\n",
    "    'sero2': 'categorical',\n",
    "    'serogrp': 'categorical',\n",
    "    'ibis_blood': 'categorical',\n",
    "    'ibis_skin': 'categorical',\n",
    "    'meno_stat': 'categorical',\n",
    "    'newld_fh': 'categorical',\n",
    "    'tempf_pe': 'continuous',\n",
    "    'pulse_pe': 'continuous',\n",
    "    'sbpre_pe': 'continuous',\n",
    "    'dbpre_pe': 'continuous',\n",
    "    'ast_l1': 'continuous',\n",
    "    'alt_l1': 'continuous',\n",
    "    'alk_l1': 'continuous',\n",
    "    'lymph_l1': 'continuous',\n",
    "    'wbc_l1': 'continuous',\n",
    "    'gran_l1': 'continuous',\n",
    "    'mono_l1': 'continuous',\n",
    "    'eos_l1': 'continuous',\n",
    "    'strev_fh': 'categorical',\n",
    "    'numb_plqs': 'categorical',\n",
    "    'sstot_sa': 'continuous',\n",
    "    'pqapi_sa': 'continuous',\n",
    "    'pqspi_sa': 'continuous',\n",
    "    'pqtpi_sa': 'continuous',\n",
    "    'ditot_sa': 'continuous',\n",
    "    'sqtot_sa': 'continuous',\n",
    "    'letot_sa': 'continuous',\n",
    "    'pf_nbs': 'continuous',\n",
    "    'rp_nbs': 'continuous',\n",
    "    'bp_nbs': 'continuous',\n",
    "    'gh_nbs': 'continuous',\n",
    "    'vt_nbs': 'continuous',\n",
    "    'sf_nbs': 'continuous',\n",
    "    're_nbs': 'continuous',\n",
    "    'mh_nbs': 'continuous',\n",
    "    'pcs': 'continuous',\n",
    "    'mcs': 'continuous',\n",
    "    'type_subject': 'categorical',\n",
    "}\n",
    "df_lm2_clinical = apply_desc(df_lm2_clinical, df_lm2_clinical_desc)\n",
    "\n",
    "df_lm2_clinical['dataset'] = 'lm2'\n",
    "df_lm2_clinical.loc[df_lm2_clinical['type_subject']=='1.0', 'dataset_type_subject'] = 'lm2-case'\n",
    "df_lm2_clinical.loc[df_lm2_clinical['type_subject']=='0.0', 'dataset_type_subject'] = 'lm2-ctrl'\n",
    "\n",
    "df_lm3_clinical = pd.read_csv(\n",
    "    data / 'LM_Slice2_Slice3_data/LM3_CaseOnly_Clinical_Entrez.csv', index_col=0,\n",
    ")\n",
    "df_lm3_clinical_desc = {\n",
    "    'pid': 'id',\n",
    "    'batch': 'label',\n",
    "    'enroll_yr': 'label',\n",
    "    'gender': 'categorical',\n",
    "    'age': 'continuous',\n",
    "    'hispa_dg': 'categorical',\n",
    "    'race1_dg': 'categorical',\n",
    "    'race2_dg': 'categorical',\n",
    "    'time_en': 'continuous',\n",
    "    'rash_mr': 'categorical',\n",
    "    'flulike_mr': 'categorical',\n",
    "    'neuro_mr': 'categorical',\n",
    "    'carditis_mr': 'categorical',\n",
    "    'arthritis_mr': 'categorical',\n",
    "    'cur_sxnum': 'continuous',\n",
    "    'time_tx': 'continuous',\n",
    "    'ax_cur': 'categorical',\n",
    "    'ax_tot': 'continuous',\n",
    "    'pretx_inax': 'categorical',\n",
    "    'st_exp': 'categorical',\n",
    "    'elres_l2': 'categorical',\n",
    "    'wbmto_l2': 'continuous',\n",
    "    'wbgto_l2': 'continuous',\n",
    "    'serogrp': 'categorical',\n",
    "    'tempf_pe': 'continuous',\n",
    "    'plssi_pe': 'continuous',\n",
    "    'sbpsi_pe': 'continuous',\n",
    "    'dbpsi_pe': 'continuous',\n",
    "    'ast_l1': 'continuous',\n",
    "    'alt_l1': 'continuous',\n",
    "    'alk_l1': 'continuous',\n",
    "    'lymph_l1': 'continuous',\n",
    "    'wbc_l1': 'continuous',\n",
    "    'gran_l1': 'continuous',\n",
    "    'mono_l1': 'continuous',\n",
    "    'eos_l1': 'continuous',\n",
    "    'sstot_sa': 'continuous',\n",
    "    'pqapi_sa': 'continuous',\n",
    "    'pqspi_sa': 'continuous',\n",
    "    'pqtpi_sa': 'continuous',\n",
    "    'ditot_sa': 'continuous',\n",
    "    'sqtot_sa': 'continuous',\n",
    "    'letot_sa': 'continuous',\n",
    "    'pf_nbs': 'continuous',\n",
    "    'rp_nbs': 'continuous',\n",
    "    'bp_nbs': 'continuous',\n",
    "    'gh_nbs': 'continuous',\n",
    "    'vt_nbs': 'continuous',\n",
    "    'sf_nbs': 'continuous',\n",
    "    're_nbs': 'continuous',\n",
    "    'mh_nbs': 'continuous',\n",
    "    'pcs': 'continuous',\n",
    "    'mcs': 'continuous',\n",
    "    'type_subject': 'categorical',\n",
    "    'visit': 'timepoint',\n",
    "}\n",
    "df_lm3_clinical = apply_desc(df_lm3_clinical, df_lm3_clinical_desc)\n",
    "\n",
    "df_lm3_clinical['dataset'] = 'lm3'\n",
    "df_lm3_clinical['dataset_type_subject'] = 'lm3-case'\n",
    "\n",
    "equivalent = [\n",
    "    dict(id='dbp_dbp', lm2='dbpre_pe', lm3='dbpsi_pe'),\n",
    "    dict(id='sbp_sbp', lm2='sbpre_pe', lm3='sbpsi_pe'),\n",
    "    dict(id='pulse', lm2='pulse_pe', lm3='plssi_pe'),\n",
    "    dict(id='time_till_treatment', lm2='durat_tx', lm3='time_tx'),\n",
    "    dict(id='time_till_enrollment', lm2='durat', lm3='time_en'),\n",
    "]\n",
    "actually_different = [\n",
    "    'visit',\n",
    "    'batch',\n",
    "    'pid',\n",
    "]\n",
    "certainly_different = [\n",
    "    dict(lm2='meno_stat'),\n",
    "    dict(lm3='rash_mr'),\n",
    "    dict(lm3='carditis_mr'),\n",
    "    dict(lm3='arthritis_mr'),\n",
    "    dict(lm3='flulike_mr'),\n",
    "]\n",
    "\n",
    "for r in equivalent:\n",
    "    df_lm2_clinical[r['id']] = df_lm2_clinical[r['lm2']]\n",
    "    df_lm3_clinical[r['id']] = df_lm3_clinical[r['lm3']]\n",
    "\n",
    "for c in actually_different:\n",
    "    df_lm2_clinical.rename({ c: c+'-lm2' }, inplace=True, axis=1)\n",
    "    df_lm3_clinical.rename({ c: c+'-lm3' }, inplace=True, axis=1)\n",
    "    \n",
    "common_clinical_columns = set(df_lm2_clinical.columns) & set(df_lm3_clinical.columns)\n",
    "disjoint_clinical_columns = set(df_lm2_clinical.columns) ^ set(df_lm3_clinical.columns)\n",
    "\n",
    "inner_clinical_columns = set(common_clinical_columns) \\\n",
    "  - set(actually_different) \\\n",
    "  | {r['id'] for r in equivalent}\n",
    "\n",
    "outer_clinical_columns_lm2 = set(common_clinical_columns) \\\n",
    "  - set(actually_different) \\\n",
    "  | {r['id'] for r in equivalent} \\\n",
    "  | {c + '-lm2' for c in actually_different }\n",
    "    \n",
    "outer_clinical_columns_lm3 = set(common_clinical_columns) \\\n",
    "  - set(actually_different) \\\n",
    "  | {r['id'] for r in equivalent} \\\n",
    "  | {c + '-lm3' for c in actually_different }\n",
    "\n",
    "df_lm23_inner_clinical = pd.concat([\n",
    "    df_lm2_clinical[inner_clinical_columns],\n",
    "    df_lm3_clinical[inner_clinical_columns],\n",
    "], axis=0)\n",
    "df_lm23_inner_clinical\n",
    "\n",
    "df_lm23_outer_clinical = pd.concat([\n",
    "    df_lm2_clinical,\n",
    "    df_lm3_clinical,\n",
    "], axis=0)\n",
    "df_lm23_outer_clinical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf8f72e-22d9-47b3-a05e-ac777d54f062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain boolean masks for different categories\n",
    "m_ptlds = df_lm23_outer_clinical['dataset_type_subject']==\"lm3-case\"\n",
    "m_healthy = df_lm23_outer_clinical['dataset_type_subject']==\"lm2-ctrl\"\n",
    "m_acute = (df_lm23_outer_clinical['visit-lm2'] == '1') & (df_lm23_outer_clinical['dataset_type_subject'] == 'lm2-case')\n",
    "m_recovery = (df_lm23_outer_clinical['visit-lm2'] != '1') & (df_lm23_outer_clinical['dataset_type_subject'] == 'lm2-case')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa57213",
   "metadata": {},
   "source": [
    "## LM2/LM3 RNAseq Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ea4347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_pca(df, with_ratio=False):\n",
    "    pca = PCA()\n",
    "    pca.fit(df.T)\n",
    "    return pd.DataFrame(\n",
    "        pca.transform(df.T),\n",
    "        index=df.columns,\n",
    "        columns=[\n",
    "            'PC-{}{}'.format(n, ' ({:.3f}%)'.format(_r*100) if with_ratio else '')\n",
    "            for n, _r in enumerate(pca.explained_variance_ratio_, start=1)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b7c157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# healthy/acute from lm2\n",
    "df_lm2_rnaseq = pd.read_csv(data / 'LM_Slice2_Slice3_data/LM2_Genetic_Entrez.csv', index_col=0)\n",
    "df_lm2_genetic = transcripts_to_genes(df_lm2_rnaseq, strategy='sum')\n",
    "df_lm2_genetic.index = df_lm2_genetic.index.map(lookup)\n",
    "df_lm2_genetic_norm = df_lm2_genetic.loc[:, ~m_recovery]\n",
    "df_lm2_genetic_norm = filter_by_expr(\n",
    "    df_lm2_genetic_norm,\n",
    "    design=df_lm2_clinical.loc[df_lm2_genetic.columns, 'type_subject'].astype(float).astype(int),\n",
    ")\n",
    "df_lm2_genetic_norm = log2_normalize(df_lm2_genetic_norm)\n",
    "df_lm2_genetic_norm = zscore_normalize(df_lm2_genetic_norm.T).T\n",
    "df_lm2_genetic_norm = quantile_normalize(df_lm2_genetic_norm)\n",
    "df_lm2_genetic_norm_pca = do_pca(df_lm2_genetic_norm)\n",
    "\n",
    "# ptld from lm3\n",
    "df_lm3_rnaseq = pd.read_csv(data / 'LM_Slice2_Slice3_data/LM3_CaseOnly_Genetic_Entrez.csv', index_col=0)\n",
    "df_lm3_genetic = transcripts_to_genes(df_lm3_rnaseq, strategy='sum')\n",
    "df_lm3_genetic.index = df_lm3_genetic.index.map(lookup)\n",
    "df_lm3_genetic_norm = df_lm3_genetic\n",
    "df_lm3_genetic_norm = filter_by_expr(\n",
    "    df_lm3_genetic_norm,\n",
    "    design=df_lm3_clinical.loc[df_lm3_genetic.columns, 'type_subject'].astype(float).astype(int),\n",
    ")\n",
    "df_lm3_genetic_norm = log2_normalize(df_lm3_genetic_norm)\n",
    "df_lm3_genetic_norm = quantile_normalize(df_lm3_genetic_norm)\n",
    "df_lm3_genetic_norm = zscore_normalize(df_lm3_genetic_norm.T).T\n",
    "df_lm3_genetic_norm_pca = do_pca(df_lm3_genetic_norm)\n",
    "\n",
    "# joint lm2/lm3\n",
    "df_lm23_genetic = pd.concat([df_lm2_genetic.loc[:, ~m_recovery], df_lm3_genetic], axis=1)\n",
    "df_lm23_genetic_norm = df_lm23_genetic\n",
    "df_lm23_genetic_norm = filter_by_expr(\n",
    "    df_lm23_genetic,\n",
    "    design=df_lm23_inner_clinical['dataset_type_subject'].map(\n",
    "        lambda d: {\n",
    "            'lm2-ctrl': 0,\n",
    "            'lm2-case': 1,\n",
    "            'lm3-case': 2,\n",
    "        }[d]\n",
    "    ),\n",
    ")\n",
    "df_lm23_genetic_norm = log2_normalize(df_lm23_genetic_norm)\n",
    "df_lm23_genetic_norm = quantile_normalize(df_lm23_genetic_norm)\n",
    "df_lm23_genetic_norm = zscore_normalize(df_lm23_genetic_norm.T).T\n",
    "df_lm23_genetic_norm_pca = do_pca(df_lm23_genetic_norm, with_ratio=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93ee7c1-f0c0-4391-abbb-9e5295f446ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lm23_outer_clinical.loc[m_ptlds, 'Cohort'] = f'PTLD (n={m_ptlds.sum()})'\n",
    "df_lm23_outer_clinical.loc[m_healthy, 'Cohort'] = f'Healthy (n={m_healthy.sum()})'\n",
    "df_lm23_outer_clinical.loc[m_acute, 'Cohort'] = f'Acute LD (n={m_acute.sum()})'\n",
    "# df_lm23_outer_clinical.loc[m_recovery, 'Cohort'] = f'LD Convalescent (n={m_recovery.sum()})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6a1985-75c6-48f2-9f34-31027b195178",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    pd.concat([\n",
    "        df_lm23_genetic_norm_pca,\n",
    "        df_lm23_outer_clinical.loc[~m_recovery],\n",
    "    ], axis=1),\n",
    "    x=df_lm23_genetic_norm_pca.columns[0],\n",
    "    y=df_lm23_genetic_norm_pca.columns[1],\n",
    "    color='Cohort',\n",
    ")\n",
    "fig.update_layout(\n",
    "    autosize=True,\n",
    "    width=1000,\n",
    "    height=600,\n",
    "    legend={'itemsizing': 'constant'},\n",
    ")\n",
    "fig.write_image(figures/'fig1.svg')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c318160c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_lm23_outer_clinical['time_en_yr'] = df_lm23_outer_clinical['time_en'] / 365\n",
    "df_lm23_outer_clinical['6mo'] = df_lm23_outer_clinical.apply(lambda r: ('Acute LD' if r['type_subject'] == '1.0' else 'Healthy') if pd.isna(r['time_en_yr']) else ('PTLD >6mo' if r['time_en_yr'] > 0.5 else 'PTLD <6mo'), axis=1)\n",
    "count_lookup = df_lm23_outer_clinical['6mo'].value_counts().to_dict()\n",
    "df_lm23_outer_clinical['6mo'] = df_lm23_outer_clinical['6mo'].apply(lambda f: f\"{f} ({count_lookup[f]})\")\n",
    "\n",
    "fig = px.scatter(\n",
    "    pd.concat([\n",
    "        df_lm23_genetic_norm_pca,\n",
    "        df_lm23_outer_clinical.loc[~m_recovery],\n",
    "    ], axis=1),\n",
    "    x=df_lm23_genetic_norm_pca.columns[0],\n",
    "    y=df_lm23_genetic_norm_pca.columns[1],\n",
    "    color='6mo',\n",
    ")\n",
    "fig.update_layout(\n",
    "    autosize=True,\n",
    "    width=1000,\n",
    "    height=600,\n",
    "    legend={'itemsizing': 'constant'},\n",
    ")\n",
    "fig.write_image(figures/'figS1.svg')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25f17ec-76ee-4f78-a92d-4064411897ca",
   "metadata": {},
   "source": [
    "## Differential Expression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439d45ab-ecac-468c-bcb7-44b79823407c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lm2_genetic_ctrl = df_lm2_genetic.loc[:, m_healthy]\n",
    "df_lm2_genetic_case_v1 = df_lm2_genetic.loc[:, m_acute]\n",
    "df_lm3_genetic_case = df_lm3_genetic\n",
    "df_lm2_genetic_lm3_genetic = pd.concat([df_lm2_genetic, df_lm3_genetic_case], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f70cda6-a39f-4a62-9a70-db87496a9341",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lm2_genetic_ctrl__lm2_genetic_case_v1 = limma_voom_differential_expression(\n",
    "    df_lm2_genetic_ctrl,\n",
    "    df_lm2_genetic_case_v1,\n",
    "    df_lm2_genetic_lm3_genetic,\n",
    "    voom_design=True, filter_genes=True,\n",
    ")\n",
    "\n",
    "df_lm2_genetic_ctrl__lm3_genetic_case = limma_voom_differential_expression(\n",
    "    df_lm2_genetic_ctrl,\n",
    "    df_lm3_genetic_case,\n",
    "    df_lm2_genetic_lm3_genetic,\n",
    "    voom_design=True, filter_genes=True,\n",
    ")\n",
    "\n",
    "df_lm2_genetic_case_v1__lm3_genetic_case = limma_voom_differential_expression(\n",
    "    df_lm2_genetic_case_v1,\n",
    "    df_lm3_genetic_case,\n",
    "    df_lm2_genetic_lm3_genetic,\n",
    "    voom_design=True, filter_genes=True,\n",
    ")\n",
    "\n",
    "cutoff = 0.01\n",
    "\n",
    "lm2_ctrl__lm2_case_v1_up = {\n",
    "    lookup(gene)\n",
    "    for gene in df_lm2_genetic_ctrl__lm2_genetic_case_v1[\n",
    "        ((df_lm2_genetic_ctrl__lm2_genetic_case_v1['adj.P.Val'] < cutoff) & (df_lm2_genetic_ctrl__lm2_genetic_case_v1['t'] > 0))\n",
    "    ].index\n",
    "}\n",
    "\n",
    "lm2_ctrl__lm3_case_up = {\n",
    "    lookup(gene)\n",
    "    for gene in df_lm2_genetic_ctrl__lm3_genetic_case[\n",
    "        ((df_lm2_genetic_ctrl__lm3_genetic_case['adj.P.Val'] < cutoff) & (df_lm2_genetic_ctrl__lm3_genetic_case['t'] > 0))\n",
    "    ].index\n",
    "}\n",
    "\n",
    "lm2_case_v1__lm3_case_up = {\n",
    "    lookup(gene)\n",
    "    for gene in df_lm2_genetic_case_v1__lm3_genetic_case[\n",
    "        ((df_lm2_genetic_case_v1__lm3_genetic_case['adj.P.Val'] < cutoff) & (df_lm2_genetic_case_v1__lm3_genetic_case['t'] > 0))\n",
    "    ].index\n",
    "}\n",
    "\n",
    "lm2_ctrl__lm2_case_v1_dn = {\n",
    "    lookup(gene)\n",
    "    for gene in df_lm2_genetic_ctrl__lm2_genetic_case_v1[\n",
    "        ((df_lm2_genetic_ctrl__lm2_genetic_case_v1['adj.P.Val'] < cutoff) & (df_lm2_genetic_ctrl__lm2_genetic_case_v1['t'] < 0))\n",
    "    ].index\n",
    "}\n",
    "\n",
    "lm2_ctrl__lm3_case_dn = {\n",
    "    lookup(gene)\n",
    "    for gene in df_lm2_genetic_ctrl__lm3_genetic_case[\n",
    "        ((df_lm2_genetic_ctrl__lm3_genetic_case['adj.P.Val'] < cutoff) & (df_lm2_genetic_ctrl__lm3_genetic_case['t'] < 0))\n",
    "    ].index\n",
    "}\n",
    "\n",
    "lm2_case_v1__lm3_case_dn = {\n",
    "    lookup(gene)\n",
    "    for gene in df_lm2_genetic_case_v1__lm3_genetic_case[\n",
    "        ((df_lm2_genetic_case_v1__lm3_genetic_case['adj.P.Val'] < cutoff) & (df_lm2_genetic_case_v1__lm3_genetic_case['t'] < 0))\n",
    "    ].index\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce37ac4b-6abe-4c2e-871d-3a99ac1ff8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "genesets = {\n",
    "    'Acute LD Up': lm2_ctrl__lm2_case_v1_up,\n",
    "    'PTLD Up': lm2_ctrl__lm3_case_up,\n",
    "    'Acute LD Down': lm2_ctrl__lm2_case_v1_dn,\n",
    "    'PTLD Down': lm2_ctrl__lm3_case_dn,\n",
    "    'Acute LD => PTLD': lm2_case_v1__lm3_case_up,\n",
    "    'Acute LD <= PTLD': lm2_case_v1__lm3_case_dn,\n",
    "    'Acute LD + PTLD Up': lm2_ctrl__lm2_case_v1_up & lm2_ctrl__lm3_case_up,\n",
    "    'Acute LD + PTLD Down': lm2_ctrl__lm2_case_v1_dn & lm2_ctrl__lm3_case_dn,\n",
    "}\n",
    "\n",
    "print('\\n'.join([\n",
    "    f\"{label:20} {len(geneset)}\"\n",
    "    for label, geneset in genesets.items()\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f31dc37",
   "metadata": {},
   "source": [
    "## Enrichment Analysis\n",
    "\n",
    "We submit the differentially expressed genes to [Enrichr](https://maayanlab.cloud/Enrichr/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc1c505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original code to generate these\n",
    "# userlists = {\n",
    "#     label: EnrichrUserList(genes, description=label)\n",
    "#     for label, genes in genesets.items()\n",
    "# }\n",
    "\n",
    "# The user lists in enrichr\n",
    "userlists = {\n",
    "  userlist.description: userlist\n",
    "  for userlist in [\n",
    "    EnrichrUserList.from_url('https://maayanlab.cloud/Enrichr/enrich?dataset=5c8c3715899dbaa6ce7aa17d3fe0e77d'),\n",
    "    EnrichrUserList.from_url('https://maayanlab.cloud/Enrichr/enrich?dataset=4a58c5ae103e3fa93861d231a9718f54'),\n",
    "    EnrichrUserList.from_url('https://maayanlab.cloud/Enrichr/enrich?dataset=1954a8136b6aa8c0b73b1cff30ad5280'),\n",
    "    EnrichrUserList.from_url('https://maayanlab.cloud/Enrichr/enrich?dataset=00e156d32ab62844391abaf9e3b0b823'),\n",
    "    EnrichrUserList.from_url('https://maayanlab.cloud/Enrichr/enrich?dataset=41c885f2b79be29e03211733ca32d137'),\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df51032",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown('\\n'.join(\n",
    "    f'- {label} [{len(userlist.genes)}]: <{userlist.link}>' for label, userlist in userlists.items()\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e95b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "libraries = [\n",
    "    'GO_Biological_Process_2021',\n",
    "    'KEGG_2021_Human',\n",
    "    'WikiPathways_2019_Human',\n",
    "    'Human_Phenotype_Ontology',\n",
    "    'MGI_Mammalian_Phenotype_Level_4_2021',\n",
    "    'GWAS_Catalog_2019',\n",
    "]\n",
    "\n",
    "enrichment = []\n",
    "for label, userlist in userlists.items():\n",
    "  for library in libraries:\n",
    "    df = userlist[library]\n",
    "    enrichment.append((label, library, df[df['adjusted_pvalue'] < 0.01]))\n",
    "\n",
    "df_enrichment = pd.DataFrame([\n",
    "    dict(row.to_dict(), geneset=geneset, library=library)\n",
    "    for geneset, library, d in enrichment\n",
    "    for i, row in d.iterrows()\n",
    "]).set_index(['geneset', 'library', 'term'])\n",
    "df_enrichment.to_csv(figures / 'TableS2.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28902ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Enrichr Compressed Bar Chart Figure Appyter\n",
    "#  https://appyters.maayanlab.cloud/Enrichr_compressed_bar_chart_figure/\n",
    "\n",
    "import re\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "artifact = re.compile(r'\\s+\\(?\\w{2}:\\w+\\)?\\s+')\n",
    "annot_dict = {}\n",
    "\n",
    "def enrichr_figure(all_terms,all_pvalues, all_adjusted_pvalues, plot_names, all_libraries, fig_format, bar_color): \n",
    "    \n",
    "    # rows and columns depend on number of Enrichr libraries submitted \n",
    "    rows = []\n",
    "    cols = []\n",
    "    \n",
    "    # Bar colors\n",
    "    if bar_color!= 'lightgrey':\n",
    "        bar_color_not_sig = 'lightgrey'\n",
    "        edgecolor=None\n",
    "        linewidth=0\n",
    "    else:\n",
    "        bar_color_not_sig = 'white'\n",
    "        edgecolor='black'\n",
    "        linewidth=1\n",
    "    \n",
    "    # If only 1 Enrichr library selected, make simple plot \n",
    "    if len(all_libraries)==1:\n",
    "        #fig,axes = plt.subplots(1, 1,figsize=[8.5,6])\n",
    "        plt.figure(figsize=(12,6))\n",
    "        rows = [0]\n",
    "        cols = [0]\n",
    "        i = 0 \n",
    "        bar_colors = [bar_color if (x < 0.05) else bar_color_not_sig for x in all_pvalues[i]]\n",
    "        fig = sns.barplot(x=np.log10(all_pvalues[i])*-1, y=all_terms[i], palette=bar_colors, edgecolor=edgecolor, linewidth=linewidth)\n",
    "        fig.axes.get_yaxis().set_visible(False)\n",
    "        fig.set_title(all_libraries[i].replace('_',' '),fontsize=26)\n",
    "        fig.set_xlabel('-Log10(p-value)',fontsize=25)\n",
    "        fig.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        fig.tick_params(axis='x', which='major', labelsize=20)\n",
    "        if max(np.log10(all_pvalues[i])*-1)<1:\n",
    "            fig.xaxis.set_ticks(np.arange(0, max(np.log10(all_pvalues[i])*-1), 0.1))\n",
    "        for ii,annot in enumerate(all_terms[i]):\n",
    "            if annot in annot_dict.keys():\n",
    "                annot = annot_dict[annot]\n",
    "            if all_adjusted_pvalues[i][ii] < 0.05:\n",
    "                annot = '  *'.join([annot, str(str(np.format_float_scientific(all_pvalues[i][ii],precision=2)))]) \n",
    "            else:\n",
    "                annot = '  '.join([annot, str(str(np.format_float_scientific(all_pvalues[i][ii],precision=2)))])\n",
    "\n",
    "            title_start= max(fig.axes.get_xlim())/200\n",
    "            fig.text(title_start,ii,annot,ha='left',wrap = True, fontsize = 26)\n",
    "            fig.patch.set_edgecolor('black')  \n",
    "            fig.patch.set_linewidth('2')\n",
    "        \n",
    "    \n",
    "    # If there are an even number of Enrichr libraries below 6\n",
    "    # Plots 1x2 or 2x2\n",
    "    else:\n",
    "        if len(all_libraries) % 2 == 0 and len(all_libraries) < 5:\n",
    "                for i in range(0,int(len(all_libraries)/2)):    \n",
    "                    rows = rows + [i]*2\n",
    "                    cols = list(range(0,2))*int(len(all_libraries)/2)    \n",
    "                fig, axes = plt.subplots(len(np.unique(rows)), len(np.unique(cols)),figsize=[7,int(2* len(np.unique(rows)))]) \n",
    "    \n",
    "        \n",
    "        # All other # of libraries 6 and above will have 3 columns and a flexible number of rows to accomodate all plots\n",
    "        else:\n",
    "            for i in range(0,int(np.ceil(len(all_libraries)/3))):\n",
    "                rows = rows + [i]*3\n",
    "                cols = list(range(0,3))*int(np.ceil(len(all_libraries)/3))\n",
    "            fig, axes = plt.subplots(len(np.unique(rows)), len(np.unique(cols)),figsize=[8,int(2* len(np.unique(rows)))])\n",
    "           \n",
    "        # If final figure only has one row...\n",
    "        if len(np.unique(rows))==1:\n",
    "            for i,library_name in enumerate(all_libraries):\n",
    "                bar_colors = [bar_color if (x < 0.05) else bar_color_not_sig for x in all_pvalues[i]]\n",
    "                sns.barplot(x=np.log10(all_pvalues[i])*-1, y=all_terms[i],ax=axes[i], palette=bar_colors, edgecolor=edgecolor, linewidth=linewidth)\n",
    "                axes[i].axes.get_yaxis().set_visible(False)\n",
    "                axes[i].set_title(library_name.replace('_',' '),fontsize=36)\n",
    "                axes[i].set_xlabel('-Log10(p-value)',fontsize=35)\n",
    "                axes[i].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "                axes[i].tick_params(axis='x', which='major', labelsize=30)\n",
    "                if max(np.log10(all_pvalues[i])*-1)<1:\n",
    "                    axes[i].xaxis.set_ticks(np.arange(0, max(np.log10(all_pvalues[i])*-1), 0.1))\n",
    "                for ii,annot in enumerate(all_terms[i]):\n",
    "                    if annot in annot_dict.keys():\n",
    "                        annot = annot_dict[annot]\n",
    "                    if all_adjusted_pvalues[i][ii] < 0.05:\n",
    "                        annot = '  *'.join([annot, str(str(np.format_float_scientific(all_pvalues[i][ii],precision=2)))]) \n",
    "                    else:\n",
    "                        annot = '  '.join([annot, str(str(np.format_float_scientific(all_pvalues[i][ii],precision=2)))])\n",
    "\n",
    "                    title_start= max(axes[i].axes.get_xlim())/200\n",
    "                    axes[i].text(title_start,ii,annot,ha='left',wrap = True, fontsize = 36)\n",
    "                    axes[i].patch.set_edgecolor('black')  \n",
    "                    axes[i].patch.set_linewidth('2')\n",
    "\n",
    "            plt.subplots_adjust(top=4.5, right = 4.7,wspace = 0.03,hspace = 0.2)\n",
    "\n",
    "\n",
    "        # If the final figure has more than one row...\n",
    "        else:\n",
    "\n",
    "\n",
    "            for i,library_name in enumerate(all_libraries):\n",
    "                bar_colors = [bar_color if (x < 0.05) else bar_color_not_sig for x in all_pvalues[i]]\n",
    "                sns.barplot(x=np.log10(all_pvalues[i])*-1, y=all_terms[i],ax=axes[rows[i],cols[i]], palette=bar_colors, edgecolor=edgecolor, linewidth=linewidth)\n",
    "                axes[rows[i],cols[i]].axes.get_yaxis().set_visible(False)\n",
    "                axes[rows[i],cols[i]].set_title(library_name.replace('_',' '),fontsize=36)\n",
    "                axes[rows[i],cols[i]].set_xlabel('-Log10(p-value)',fontsize=35)\n",
    "                axes[rows[i],cols[i]].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "                axes[rows[i],cols[i]].tick_params(axis='x', which='major', labelsize=30)\n",
    "                if max(np.log10(all_pvalues[i])*-1)<1:\n",
    "                    axes[rows[i],cols[i]].xaxis.set_ticks(np.arange(0, max(np.log10(all_pvalues[i])*-1), 0.1))\n",
    "                for ii,annot in enumerate(all_terms[i]):\n",
    "                    if annot in annot_dict.keys():\n",
    "                        annot = annot_dict[annot]\n",
    "                    if all_adjusted_pvalues[i][ii] < 0.05:\n",
    "                        annot = '  *'.join([annot, str(str(np.format_float_scientific(all_pvalues[i][ii],precision=2)))]) \n",
    "                    else:\n",
    "                        annot = '  '.join([annot, str(str(np.format_float_scientific(all_pvalues[i][ii],precision=2)))])\n",
    "\n",
    "                    title_start = max(axes[rows[i],cols[i]].axes.get_xlim())/200\n",
    "                    axes[rows[i],cols[i]].text(title_start, ii, re.sub(artifact, ' ', annot).strip(), ha='left',wrap = True,va='center', fontsize = 24)\n",
    "                    axes[rows[i],cols[i]].patch.set_edgecolor('black')  \n",
    "                    axes[rows[i],cols[i]].patch.set_linewidth('2')\n",
    "\n",
    "            plt.subplots_adjust(top=4.8, right = 4.7,wspace = 0.03,hspace = 0.2)\n",
    "\n",
    "\n",
    "        # If >6 libraries are chosen and is not a multiple of 3, delete empty plots\n",
    "        if len(np.unique(rows))*len(np.unique(cols)) != len(all_libraries):\n",
    "            diff = (len(np.unique(rows))*len(np.unique(cols))) - len(all_libraries)\n",
    "            for i in range (1,int(diff+1)):\n",
    "                fig.delaxes(axes[rows[-i]][cols[-i]])\n",
    "    \n",
    "    # Save results \n",
    "    for plot_name in plot_names:\n",
    "        plt.savefig(str(figures/plot_name),format=fig_format, bbox_inches = 'tight')\n",
    "    \n",
    "    # Show plot \n",
    "    plt.show()\n",
    "\n",
    "for label, userlist in userlists.items():\n",
    "    print(label)\n",
    "    all_terms = []\n",
    "    all_pvalues = []\n",
    "    all_adjusted_pvalues = []\n",
    "    library_success = []\n",
    "    for lib in libraries:\n",
    "        try:\n",
    "            df_lib_top = userlist[lib].iloc[:5]\n",
    "            all_terms.append(df_lib_top['term'].tolist())\n",
    "            all_pvalues.append(df_lib_top['pvalue'].tolist())\n",
    "            all_adjusted_pvalues.append(df_lib_top['adjusted_pvalue'].tolist())\n",
    "            library_success.append(lib)\n",
    "        except:\n",
    "            print('Error for ' + lib + ' library')\n",
    "    #\n",
    "    enrichr_figure(\n",
    "        all_terms,\n",
    "        all_pvalues,\n",
    "        all_adjusted_pvalues,\n",
    "        [f\"fig2-3-{label.replace('/','-')}.pdf\"],\n",
    "        library_success,\n",
    "        'pdf', 'tomato'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7981fec",
   "metadata": {},
   "source": [
    "### KEGG Enrichment\n",
    "\n",
    "We look specifically the Herpes Enriched term in KEGG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b056c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get('https://maayanlab.cloud/Enrichr/geneSetLibrary?mode=text&libraryName=KEGG_2021_Human')\n",
    "KEGG = gmt_read_dict(res.text.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7772825",
   "metadata": {},
   "outputs": [],
   "source": [
    "venn3([\n",
    "    lm2_ctrl__lm2_case_v1_dn,\n",
    "    set(KEGG['Herpes simplex virus 1 infection']),\n",
    "    lm2_ctrl__lm3_case_up,\n",
    "], [\n",
    "    'Down Regulated Genes in Acute LD',\n",
    "    'KEGG_2021_Human: Herpes simplex virus 1 infection',\n",
    "    'Up Regulated Genes in PTLD',\n",
    "])\n",
    "plt.savefig(figures/'fig3.svg', bbox_inches='tight', pad_inches=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cea007",
   "metadata": {},
   "source": [
    "# Enrichr Signatures\n",
    "\n",
    "We load geneset biomarkers implicated in other diseases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e21453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefix_keys(*args):\n",
    "    *prefix, obj = args\n",
    "    return { (*prefix, key): value for key, value in obj.items() }\n",
    "\n",
    "def dict_union(*dicts):\n",
    "    union = {}\n",
    "    for d in dicts: union.update(d)\n",
    "    return union\n",
    "\n",
    "def union_signature(signatures):\n",
    "    return set.union(*map(set, signatures.values()))\n",
    "\n",
    "def gather_signatures(library, condition):\n",
    "    q = {k for k,v in library.items() if condition(k)}\n",
    "    display(q)\n",
    "    return { k: { lookup(vv) for vv in library[k] } for k in q }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6647a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab geneset-libraries from enrichr\n",
    "res = requests.get('https://maayanlab.cloud/Enrichr/geneSetLibrary?mode=text&libraryName=GO_Biological_Process_2018')\n",
    "GO = gmt_read_dict(res.text.split('\\n'))\n",
    "\n",
    "res = requests.get('https://maayanlab.cloud/Enrichr/geneSetLibrary?mode=text&libraryName=Disease_Perturbations_from_GEO_up')\n",
    "GEO_disease_up = gmt_read_dict(res.text.split('\\n'))\n",
    "\n",
    "res = requests.get('https://maayanlab.cloud/Enrichr/geneSetLibrary?mode=text&libraryName=Microbe_Perturbations_from_GEO_up')\n",
    "GEO_microbe_up = gmt_read_dict(res.text.split('\\n'))\n",
    "\n",
    "res = requests.get('https://maayanlab.cloud/Enrichr/geneSetLibrary?mode=text&libraryName=GWAS_Catalog_2019')\n",
    "GWAS_2019 = gmt_read_dict(res.text.split('\\n'))\n",
    "\n",
    "res = requests.get('https://maayanlab.cloud/Enrichr/geneSetLibrary?mode=text&libraryName=DisGeNET')\n",
    "DisGeNET = gmt_read_dict(res.text.split('\\n'))\n",
    "\n",
    "res = requests.get('https://maayanlab.cloud/Enrichr/geneSetLibrary?mode=text&libraryName=COVID-19_Related_Gene_Sets')\n",
    "COV = gmt_read_dict(res.text.split('\\n'))\n",
    "\n",
    "res = requests.get('https://maayanlab.cloud/Enrichr/geneSetLibrary?mode=text&libraryName=Jensen_DISEASES')\n",
    "DISEASES = gmt_read_dict(res.text.split('\\n'))\n",
    "\n",
    "res = requests.get('https://maayanlab.cloud/Enrichr/geneSetLibrary?mode=text&libraryName=Rare_Diseases_GeneRIF_Gene_Lists')\n",
    "Rare_Diseases_GeneRIF_Gene_Lists = gmt_read_dict(res.text.split('\\n'))\n",
    "\n",
    "res = requests.get('https://maayanlab.cloud/Enrichr/geneSetLibrary?mode=text&libraryName=Rare_Diseases_AutoRIF_Gene_Lists')\n",
    "Rare_Diseases_AutoRIF_Gene_Lists = gmt_read_dict(res.text.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc1ac5a-c806-4c6e-ace6-b0fd36984355",
   "metadata": {},
   "outputs": [],
   "source": [
    "signatures = dict_union(\n",
    "    prefix_keys('Term',        None, 'GO_Biological_Process_2018',\n",
    "                gather_signatures(GO, lambda k: k in {'inflammatory response (GO:0006954)', 'cellular response to molecule of bacterial origin (GO:0071219)'})),\n",
    "    prefix_keys('Viral',       'Influenza', 'Microbe_Perturbations_from_GEO_up',\n",
    "                gather_signatures(GEO_microbe_up, lambda k: 'influenza' in k.lower())),\n",
    "    prefix_keys('Viral',       'HIV', 'Microbe_Perturbations_from_GEO_up',\n",
    "                gather_signatures(GEO_microbe_up, lambda k: k == 'HIV-1 human PBMC GDS1449 microbe:221')),\n",
    "    prefix_keys('Viral',       'COVID-19', 'COVID-19_Related_Gene_Sets',\n",
    "                gather_signatures(COV, lambda k: k == 'COVID-19 patients PBMC up')),\n",
    "    prefix_keys('Bacterial',   'Tuberculosis', 'Microbe_Perturbations_from_GEO_up',\n",
    "                gather_signatures(GEO_microbe_up, lambda k: 'tuberculosis' in k.lower() and 'human pbmc' in k.lower())),\n",
    "    prefix_keys('Bacterial',   'Streptococcus', 'Microbe_Perturbations_from_GEO_up',\n",
    "                gather_signatures(GEO_microbe_up, lambda k: 'streptococcus' in k.lower() and 'human' in k.lower())),\n",
    "    prefix_keys('Bacterial',   'Pneumococcal', 'DisGeNET',\n",
    "                gather_signatures(DisGeNET, lambda k: 'pneumococcal' in k.lower())),\n",
    "    prefix_keys('Bacterial',   'E. Coli', 'Microbe_Perturbations_from_GEO_up',\n",
    "                gather_signatures(GEO_microbe_up, lambda k: 'escherichia coli' in k.lower())),\n",
    "    prefix_keys('Bacterial',   'E. Coli', 'Disease_Perturbations_from_GEO_up',\n",
    "                gather_signatures(GEO_disease_up, lambda k: 'escherichia coli' in k.lower())),\n",
    "    prefix_keys('Bacterial',   'Staphylococcus', 'Microbe_Perturbations_from_GEO_up',\n",
    "                gather_signatures(GEO_microbe_up, lambda k: 'staphylococcus' in k.lower() and 'human' in k.lower())),\n",
    "    prefix_keys('Bacterial',   'Gonorrhoeae', 'Microbe_Perturbations_from_GEO_up',\n",
    "                gather_signatures(GEO_microbe_up, lambda k: 'gonorrhoeae' in k.lower() and 'pbmc' in k.lower())),\n",
    "    prefix_keys('Bacterial',   'Sepsis', 'Disease_Perturbations_from_GEO_up',\n",
    "                gather_signatures(GEO_disease_up, lambda k: 'sepsis' in k.lower())),\n",
    "    prefix_keys('Bacterial',   'Sepsis', 'DisGeNET',\n",
    "                gather_signatures(DisGeNET, lambda k: 'sepsis' in k.lower())),\n",
    "    prefix_keys('Spirochetes', 'Syphilis', 'DisGeNET',\n",
    "                gather_signatures(DisGeNET, lambda k: 'syphilis' in k.lower())),\n",
    "    prefix_keys('Spirochetes', 'Syphilis', 'Jensen_DISEASES',\n",
    "                gather_signatures(DISEASES, lambda k: 'syphilis' in k.lower())),\n",
    "    prefix_keys('Spirochetes', 'Leptospirosis', 'DisGeNET',\n",
    "                gather_signatures(DisGeNET, lambda k: 'leptospirosis' in k.lower())),\n",
    "    prefix_keys('Spirochetes', 'Leptospirosis', 'Jensen_DISEASES',\n",
    "                gather_signatures(DISEASES, lambda k: 'leptospirosis' in k.lower())),\n",
    "    prefix_keys('Spirochetes', 'Yaws', 'Jensen_DISEASES',\n",
    "                gather_signatures(DISEASES, lambda k: 'yaws' in k.lower())),\n",
    "    prefix_keys('Spirochetes', 'Relapsing Fever', 'DisGeNET',\n",
    "                gather_signatures(DisGeNET, lambda k: 'relapsing fever' in k.lower())),\n",
    "    prefix_keys('Spirochetes', 'Relapsing Fever', 'Jensen_DISEASES',\n",
    "                gather_signatures(DISEASES, lambda k: 'relapsing fever' in k.lower())),\n",
    "    prefix_keys('Spirochetes', 'Periodontal Disease', 'DisGeNET',\n",
    "                gather_signatures(DisGeNET, lambda k: 'periodontal disease' in k.lower())),\n",
    "    prefix_keys('Spirochetes', 'Bejel', 'Rare_Diseases_GeneRIF_Gene_Lists',\n",
    "                gather_signatures(Rare_Diseases_GeneRIF_Gene_Lists, lambda k: 'bejel' in k.lower())),\n",
    "    prefix_keys('Spirochetes', 'Bejel', 'Rare_Diseases_AutoRIF_Gene_Lists',\n",
    "                gather_signatures(Rare_Diseases_AutoRIF_Gene_Lists, lambda k: 'bejel' in k.lower())),\n",
    "    prefix_keys('Spirochetes', 'Pinta', 'Rare_Diseases_AutoRIF_Gene_Lists',\n",
    "                gather_signatures(Rare_Diseases_AutoRIF_Gene_Lists, lambda k: 'pinta' in k.lower())),\n",
    "\n",
    ")\n",
    "df_signatures = pd.DataFrame([\n",
    "    {\n",
    "        'category': category,\n",
    "        'disease': disease,\n",
    "        'library': library,\n",
    "        'term': term,\n",
    "        'n_genes': len(genes)\n",
    "    }\n",
    "    for (category, disease, library, term), genes in signatures.items()\n",
    "])\n",
    "df_signatures.to_csv(figures / 'TableS1.tsv', sep='\\t')\n",
    "df_signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a520f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_universe = set.union(\n",
    "    lm2_ctrl__lm2_case_v1_up,\n",
    "    lm2_ctrl__lm3_case_up,\n",
    "    lm2_ctrl__lm2_case_v1_dn,\n",
    "    lm2_ctrl__lm3_case_dn,\n",
    ")\n",
    "inflammatory_term = {gene for (category, disease, library, term), genes in signatures.items() if category == 'Term' and term == 'inflammatory response (GO:0006954)' for gene in genes}\n",
    "bacteria_term = {gene for (category, disease, library, term), genes in signatures.items() if category == 'Term' and term == 'cellular response to molecule of bacterial origin (GO:0071219)' for gene in genes}\n",
    "bacterial_union = {gene for (category, disease, library, term), genes in signatures.items() if category == 'Bacterial' for gene in genes}\n",
    "viral_union = {gene for (category, disease, library, term), genes in signatures.items() if category == 'Viral' for gene in genes}\n",
    "spirochetes_union = {gene for (category, disease, library, term), genes in signatures.items() if category == 'Spirochetes' for gene in genes}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b405016f",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35484f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = OrderedDict([\n",
    "  ('Up Regulated Genes in Acute LD', lm2_ctrl__lm2_case_v1_up),\n",
    "  ('Up Regulated Genes in PTLD', lm2_ctrl__lm3_case_up),\n",
    "  ('Down Regulated Genes in Acute LD', lm2_ctrl__lm2_case_v1_dn),\n",
    "  ('Down Regulated Genes in PTLD', lm2_ctrl__lm3_case_dn),\n",
    "  ('Inflammatory Response (GO:0006954)', inflammatory_term & lm_universe),\n",
    "  ('Cellular Response to Molecule of Bacterial Origin (GO:0071219)', bacteria_term & lm_universe),\n",
    "  ('Bacterial Enrichr Gene Sets', bacterial_union & lm_universe),\n",
    "  ('Viral Enrichr Gene Sets', viral_union & lm_universe),\n",
    "  ('Spirochete Enrichr Gene Sets', spirochetes_union & lm_universe),\n",
    "])\n",
    "\n",
    "with plt.style.context('bmh'):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    supervenn(\n",
    "        *zip(*((v, k) for k, v in sets.items())),\n",
    "        sets_ordering='minimize gaps',\n",
    "        widths_minmax_ratio=0.1,\n",
    "        min_width_for_annotation=10,\n",
    "    )\n",
    "    plt.savefig(figures / 'fig4.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7875f2a-8331-4adc-bebb-4a9955075dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_up = (lm2_ctrl__lm2_case_v1_up & lm2_ctrl__lm3_case_up) - bacterial_union - viral_union - spirochetes_union\n",
    "consensus_dn = (lm2_ctrl__lm2_case_v1_dn & lm2_ctrl__lm3_case_dn) - bacterial_union - viral_union - spirochetes_union\n",
    "divergent = ((lm2_ctrl__lm2_case_v1_up & lm2_ctrl__lm3_case_dn) | (lm2_ctrl__lm2_case_v1_dn & lm2_ctrl__lm3_case_up)) - bacterial_union - viral_union - spirochetes_union\n",
    "len(consensus_up), len(consensus_dn), len(divergent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ed163c-ffed-40a7-b107-9d6902c8d6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant = list(consensus_up | consensus_dn | divergent)\n",
    "len(relevant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee177d9",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "We attempt to reduce the number of genes in this set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50dfd80-c3fd-462a-a8ca-24691cda578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.concat([\n",
    "    df_lm2_genetic_lm3_genetic.loc[relevant, :].T,\n",
    "    df_lm23_inner_clinical[['dataset_type_subject']],\n",
    "], axis=1).reset_index().set_index(['dataset_type_subject', 'index'])\n",
    "score = (d.var() / d.groupby(level=0).var()).mean().sort_values(ascending=False)\n",
    "sns.histplot(score)\n",
    "plt.ylabel('Genes')\n",
    "plt.xlabel('mean(total_variance / inter_group_variance)')\n",
    "plt.show()\n",
    "display(score[score>3])\n",
    "var_selected_genes = list(score[score>3].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7328a28e-3b49-4d06-945f-9adc32644148",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_defs = [\n",
    "    (\n",
    "        'Lyme v Healthy',\n",
    "        m_acute|m_ptlds, m_healthy,\n",
    "    ),\n",
    "    (\n",
    "        'Acute LD v Healthy',\n",
    "        m_acute, m_healthy,\n",
    "    ),\n",
    "    (\n",
    "        'PTLD v Healthy',\n",
    "        m_ptlds, m_healthy,\n",
    "    ),\n",
    "    (\n",
    "        'Acute LD v PTLD',\n",
    "        m_acute, m_ptlds,\n",
    "    ),\n",
    "]\n",
    "\n",
    "tasks = []\n",
    "for label, pos, neg in task_defs:\n",
    "    X = df_lm2_genetic_lm3_genetic.loc[relevant, neg|pos].T\n",
    "    y = pd.Series(np.in1d(X.index, pos[pos].index).astype(int), index=X.index)\n",
    "    tasks.append((label, X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaf3e5f-f56d-4056-b5e8-26c98d2d25cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = {}\n",
    "for label, X, y in tasks:\n",
    "    clf = LogisticRegression()#max_iter=800)\n",
    "    clf.fit(X, y)\n",
    "    ret = permutation_importance(clf, X, y, n_repeats=50, random_state=random_state)\n",
    "    importance = pd.Series(ret.importances_mean, index=X.columns).sort_values()\n",
    "    sns.histplot(importance); plt.show()\n",
    "    importances[label] = importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c830963-3825-4f46-a082-0bab1a6a2b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 0.3\n",
    "consensus = {k: (v-v.mean())/v.std() for k, v in importances.items()}\n",
    "consensus.update(var=(score-score.mean())/score.std())\n",
    "df_consensus = pd.concat(consensus.values(), axis=1).dropna()\n",
    "df_consensus.columns = consensus.keys()\n",
    "display(df_consensus)\n",
    "df_consensus_agg = df_consensus.mean(axis=1).sort_values()\n",
    "sns.histplot(df_consensus_agg)\n",
    "plt.vlines([cutoff*df_consensus_agg.std()], ymin=0,ymax=5, color='black')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Average score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1e4f42-c737-4e6f-bdc9-308c7f305ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consensus_selected = df_consensus_agg[df_consensus_agg > cutoff * df_consensus_agg.std()]\n",
    "df_consensus_selected.to_frame('Average Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dd73fc-4c7c-4557-8b49-58895a307add",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_consensus = df_consensus_selected.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b4db10-6c2e-4614-830a-7c67c69f4d87",
   "metadata": {},
   "source": [
    "## Holdout\n",
    "\n",
    "Though these genes are relevant, a feature selection bias could arrise, thus we'll do this feature selection with held out samples as to assert generalizability of our model. We will validate against these samples which will not be used for feature selection or training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8614bd88-2351-4cb6-b3a6-2cdbe8b98218",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lm2_genetic_ctrl_train, df_lm2_genetic_ctrl_test = map(lambda v: v.T, train_test_split(df_lm2_genetic_ctrl.T, random_state=random_state))\n",
    "df_lm2_genetic_case_v1_train, df_lm2_genetic_case_v1_test = map(lambda v: v.T, train_test_split(df_lm2_genetic_case_v1.T, random_state=random_state))\n",
    "df_lm3_genetic_case_train, df_lm3_genetic_case_test = map(lambda v: v.T, train_test_split(df_lm3_genetic_case.T, random_state=random_state))\n",
    "df_lm2_genetic_lm3_genetic_train, df_lm2_genetic_lm3_genetic_test = pd.concat([df_lm2_genetic_ctrl_train, df_lm2_genetic_case_v1_train, df_lm3_genetic_case_train], axis=1), pd.concat([df_lm2_genetic_ctrl_test, df_lm2_genetic_case_v1_test, df_lm3_genetic_case_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f3a8dd-0bbb-4a4d-9ce0-edb5806eb3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n'.join([\n",
    "    f\"Holdout from {df_lm2_genetic_lm3_genetic.shape=}\",\n",
    "    f\"type   {'train'                                 :15} test\",\n",
    "    f\"ctrl   {repr(df_lm2_genetic_ctrl_train.shape)   :15} {df_lm2_genetic_ctrl_test.shape}\",\n",
    "    f\"acute  {repr(df_lm2_genetic_case_v1_train.shape):15} {df_lm2_genetic_case_v1_test.shape}\",\n",
    "    f\"ptld   {repr(df_lm3_genetic_case_train.shape)   :15} {df_lm3_genetic_case_test.shape}\",\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2c4d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lm2_genetic_ctrl__lm2_genetic_case_v1 = limma_voom_differential_expression(\n",
    "    df_lm2_genetic_ctrl_train,\n",
    "    df_lm2_genetic_case_v1_train,\n",
    "    df_lm2_genetic_lm3_genetic_train,\n",
    "    voom_design=True, filter_genes=True,\n",
    ")\n",
    "\n",
    "df_lm2_genetic_ctrl__lm3_genetic_case = limma_voom_differential_expression(\n",
    "    df_lm2_genetic_ctrl_train,\n",
    "    df_lm3_genetic_case_train,\n",
    "    df_lm2_genetic_lm3_genetic_train,\n",
    "    voom_design=True, filter_genes=True,\n",
    ")\n",
    "\n",
    "df_lm2_genetic_case_v1__lm3_genetic_case = limma_voom_differential_expression(\n",
    "    df_lm2_genetic_case_v1_train,\n",
    "    df_lm3_genetic_case_train,\n",
    "    df_lm2_genetic_lm3_genetic_train,\n",
    "    voom_design=True, filter_genes=True,\n",
    ")\n",
    "\n",
    "cutoff = 0.01\n",
    "\n",
    "lm2_ctrl__lm2_case_v1_up = {\n",
    "    lookup(gene)\n",
    "    for gene in df_lm2_genetic_ctrl__lm2_genetic_case_v1[\n",
    "        ((df_lm2_genetic_ctrl__lm2_genetic_case_v1['adj.P.Val'] < cutoff) & (df_lm2_genetic_ctrl__lm2_genetic_case_v1['t'] > 0))\n",
    "    ].index\n",
    "}\n",
    "\n",
    "lm2_ctrl__lm3_case_up = {\n",
    "    lookup(gene)\n",
    "    for gene in df_lm2_genetic_ctrl__lm3_genetic_case[\n",
    "        ((df_lm2_genetic_ctrl__lm3_genetic_case['adj.P.Val'] < cutoff) & (df_lm2_genetic_ctrl__lm3_genetic_case['t'] > 0))\n",
    "    ].index\n",
    "}\n",
    "\n",
    "lm2_ctrl__lm2_case_v1_dn = {\n",
    "    lookup(gene)\n",
    "    for gene in df_lm2_genetic_ctrl__lm2_genetic_case_v1[\n",
    "        ((df_lm2_genetic_ctrl__lm2_genetic_case_v1['adj.P.Val'] < cutoff) & (df_lm2_genetic_ctrl__lm2_genetic_case_v1['t'] < 0))\n",
    "    ].index\n",
    "}\n",
    "\n",
    "lm2_ctrl__lm3_case_dn = {\n",
    "    lookup(gene)\n",
    "    for gene in df_lm2_genetic_ctrl__lm3_genetic_case[\n",
    "        ((df_lm2_genetic_ctrl__lm3_genetic_case['adj.P.Val'] < cutoff) & (df_lm2_genetic_ctrl__lm3_genetic_case['t'] < 0))\n",
    "    ].index\n",
    "}\n",
    "\n",
    "lm2_case_v1__lm3_case_up = {\n",
    "    lookup(gene)\n",
    "    for gene in df_lm2_genetic_case_v1__lm3_genetic_case[\n",
    "        ((df_lm2_genetic_case_v1__lm3_genetic_case['adj.P.Val'] < cutoff) & (df_lm2_genetic_case_v1__lm3_genetic_case['t'] > 0))\n",
    "    ].index\n",
    "}\n",
    "\n",
    "lm2_case_v1__lm3_case_dn = {\n",
    "    lookup(gene)\n",
    "    for gene in df_lm2_genetic_case_v1__lm3_genetic_case[\n",
    "        ((df_lm2_genetic_case_v1__lm3_genetic_case['adj.P.Val'] < cutoff) & (df_lm2_genetic_case_v1__lm3_genetic_case['t'] < 0))\n",
    "    ].index\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff3c01d-9b6c-4fbe-b7ef-5d05bf7328a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_universe = set.union(\n",
    "    lm2_ctrl__lm2_case_v1_up,\n",
    "    lm2_ctrl__lm3_case_up,\n",
    "    lm2_ctrl__lm2_case_v1_dn,\n",
    "    lm2_ctrl__lm3_case_dn,\n",
    ")\n",
    "consensus_up = (lm2_ctrl__lm2_case_v1_up & lm2_ctrl__lm3_case_up) - bacterial_union - viral_union - spirochetes_union\n",
    "consensus_dn = (lm2_ctrl__lm2_case_v1_dn & lm2_ctrl__lm3_case_dn) - bacterial_union - viral_union - spirochetes_union\n",
    "divergent = ((lm2_ctrl__lm2_case_v1_up & lm2_ctrl__lm3_case_dn) | (lm2_ctrl__lm2_case_v1_dn & lm2_ctrl__lm3_case_up)) - bacterial_union - viral_union - spirochetes_union\n",
    "relevant = list(consensus_up | consensus_dn | divergent)\n",
    "display((len(consensus_up), len(consensus_dn), len(divergent)))\n",
    "display(len(relevant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c602301d-697c-4fec-a630-e666baafce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.concat([\n",
    "    df_lm2_genetic_lm3_genetic_train.loc[relevant, :].T,\n",
    "    df_lm23_inner_clinical[['dataset_type_subject']],\n",
    "], axis=1).reset_index().set_index(['dataset_type_subject', 'index'])\n",
    "score = (d.var() / d.groupby(level=0).var()).mean().sort_values(ascending=False)\n",
    "sns.histplot(score)\n",
    "plt.ylabel('Genes')\n",
    "plt.xlabel('mean(total_variance / inter_group_variance)')\n",
    "plt.show()\n",
    "display(score[score>3])\n",
    "var_selected_genes = list(score[score>3].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc2f3d1-2b33-438d-8bae-58ef8efdbeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tasks = []\n",
    "for label, pos, neg in task_defs:\n",
    "    X_train = df_lm2_genetic_lm3_genetic_train.loc[relevant, neg|pos].T\n",
    "    y_train = X_train.index.to_series().isin(pos[pos].index).astype(int)\n",
    "    X_test = df_lm2_genetic_lm3_genetic_test.loc[relevant, neg|pos].T\n",
    "    y_test = X_test.index.to_series().isin(pos[pos].index).astype(int)\n",
    "    train_tasks.append((label, X_train, y_train, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125ba8f0-673f-4e4c-83d1-ab8936defa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = {}\n",
    "for label, X_train, y_train, _X_test, _y_test in train_tasks:\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train, y_train)\n",
    "    ret = permutation_importance(clf, X_train, y_train, n_repeats=50, random_state=random_state)\n",
    "    importance = pd.Series(ret.importances_mean, index=X_train.columns).sort_values()\n",
    "    sns.histplot(importance); plt.show()\n",
    "    importances[label] = importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022476f8-c6e8-4a79-bf05-78f7586de483",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 0.3\n",
    "consensus = {k: (v-v.mean())/v.std() for k, v in importances.items()}\n",
    "consensus.update(var=(score-score.mean())/score.std())\n",
    "df_consensus = pd.concat(consensus.values(), axis=1).dropna()\n",
    "df_consensus.columns = consensus.keys()\n",
    "display(df_consensus)\n",
    "df_consensus_agg = df_consensus.mean(axis=1).sort_values()\n",
    "sns.histplot(df_consensus_agg)\n",
    "plt.vlines([cutoff*df_consensus_agg.std()], ymin=0,ymax=5, color='black')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Average score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e94d9f7-1259-4266-be6b-d4f36eb6d35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consensus_selected = df_consensus_agg[df_consensus_agg > cutoff * df_consensus_agg.std()]\n",
    "df_consensus_selected.to_frame('Average Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03b4c70-6218-4ef8-948d-14a5c49eba26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib_venn import venn2\n",
    "venn2([set(df_consensus_selected.index), set(final_consensus)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb62a4b-78a0-4f9e-9ad1-49508a900a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_label = 'Biomarker'\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "fig2, ((ax2_11, ax2_12), (ax2_21, ax2_22)) = plt.subplots(2, 2, figsize=(12, 12))\n",
    "for (label, X_train, y_train, X_test, y_test), ax2_n in zip(train_tasks, (ax2_11, ax2_12, ax2_21, ax2_22)):\n",
    "    # add determinism\n",
    "    rs = np.random.RandomState(seed=random_state)\n",
    "    clf = Pipeline([('scaler', StandardScaler()), ('lr', LogisticRegression())])\n",
    "    # how consistent are these results across different stratified shuffle splits\n",
    "    _score, _permutation_scores, pvalue = permutation_test_score(clf, X_train, y_train,\n",
    "      n_permutations=200,\n",
    "      cv=StratifiedShuffleSplit(n_splits=5, test_size=0.5, random_state=rs),\n",
    "      random_state=rs,\n",
    "    )\n",
    "    full_label = f\"{features_label} {label} (p={pvalue:.3f})\"\n",
    "    # during training, we oversample to maximize utilization of the available\n",
    "    #  samples but learn a balanced dataset\n",
    "    rus = RandomOverSampler(random_state=rs)\n",
    "    X_train_resamp, y_train_resamp = X_train, y_train\n",
    "    X_train_resamp, y_train_resamp = rus.fit_resample(X_train, y_train)\n",
    "    clf.fit(X_train_resamp, y_train_resamp)\n",
    "    # during testing, we undersample such that we have a 50/50 prior\n",
    "    #  because the actual distribution is not balanced and skewed to i.e. PTLD & Acute Lyme\n",
    "    rus = RandomUnderSampler(random_state=rs)\n",
    "    X_test_resamp, y_test_resamp = X_test, y_test\n",
    "    X_test_resamp, y_test_resamp = rus.fit_resample(X_test, y_test)\n",
    "    plot_confusion_matrix(clf, X_test_resamp, y_test_resamp, ax=ax2_n)\n",
    "    ax2_n.set_title(full_label)\n",
    "    plot_precision_recall_curve(clf, X_test_resamp, y_test_resamp, name=full_label, ax=ax2)\n",
    "    plot_roc_curve(clf, X_test_resamp, y_test_resamp, name=full_label, ax=ax1)\n",
    "ax1.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1),\n",
    "          fancybox=True, shadow=True, ncol=1)\n",
    "ax2.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1),\n",
    "          fancybox=True, shadow=True, ncol=1)\n",
    "fig.show()\n",
    "fig2.show()\n",
    "fig.savefig(figures/'fig5.svg', bbox_inches='tight', pad_inches=0.2)\n",
    "fig2.savefig(figures/'fig5.svg', bbox_inches='tight', pad_inches=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309dc1c9-d75d-4e8c-ad18-bc805e8f233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KLHL11 and UTF1 are the best performers, and are highly correlated to PC-1 & PC-2\n",
    "\n",
    "features_label = 'KLHL11-UTF1'\n",
    "features = ['KLHL11', 'UTF1']\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "fig2, ((ax2_11, ax2_12), (ax2_21, ax2_22)) = plt.subplots(2, 2, figsize=(12, 12))\n",
    "for (label, X_train, y_train, X_test, y_test), ax2_n in zip(train_tasks, (ax2_11, ax2_12, ax2_21, ax2_22)):\n",
    "    X_train = X_train.loc[:, features]\n",
    "    X_test = X_test.loc[:, features]\n",
    "    rs = np.random.RandomState(seed=random_state)\n",
    "    clf = Pipeline([('scaler', StandardScaler()), ('lr', LogisticRegression())])\n",
    "    # how consistent are these results across different stratified shuffle splits\n",
    "    _score, _permutation_scores, pvalue = permutation_test_score(clf, X_train, y_train,\n",
    "      n_permutations=200,\n",
    "      cv=StratifiedShuffleSplit(n_splits=5, test_size=0.5, random_state=rs),\n",
    "      random_state=rs,\n",
    "    )\n",
    "    full_label = f\"{features_label} {label} (p={pvalue:.3f})\"\n",
    "    # during training, we oversample to maximize utilization of the available\n",
    "    #  samples but learn a balanced dataset\n",
    "    rus = RandomOverSampler(random_state=rs)\n",
    "    X_train_resamp, y_train_resamp = X_train, y_train\n",
    "    X_train_resamp, y_train_resamp = rus.fit_resample(X_train, y_train)\n",
    "    clf.fit(X_train_resamp, y_train_resamp)\n",
    "    # during testing, we undersample such that we have a 50/50 prior\n",
    "    #  because the actual distribution is not balanced and skewed to i.e. PTLD & Acute Lyme\n",
    "    rus = RandomUnderSampler(random_state=rs)\n",
    "    X_test_resamp, y_test_resamp = X_test, y_test\n",
    "    X_test_resamp, y_test_resamp = rus.fit_resample(X_test, y_test)\n",
    "    plot_confusion_matrix(clf, X_test_resamp, y_test_resamp, ax=ax2_n)\n",
    "    ax2_n.set_title(full_label)\n",
    "    plot_precision_recall_curve(clf, X_test_resamp, y_test_resamp, name=full_label, ax=ax2)\n",
    "    plot_roc_curve(clf, X_test_resamp, y_test_resamp, name=full_label, ax=ax1)\n",
    "ax1.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1),\n",
    "          fancybox=True, shadow=True, ncol=1)\n",
    "ax2.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1),\n",
    "          fancybox=True, shadow=True, ncol=1)\n",
    "fig.show()\n",
    "fig2.show()\n",
    "fig.savefig(figures/'figS3.svg', bbox_inches='tight', pad_inches=0.2)\n",
    "fig2.savefig(figures/'figS3.svg', bbox_inches='tight', pad_inches=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dcfca7",
   "metadata": {},
   "source": [
    "## Supplemental Analysis: Single Biomarker Performance\n",
    "\n",
    "We evaluate each individual biomarker on its performance as a standalone predictor for each classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3832d466",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for g in final_consensus:\n",
    "    features = [g]\n",
    "    for label, X, y in tasks:\n",
    "        rs = np.random.RandomState(seed=random_state)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X.loc[:, features], y, test_size=0.5, random_state=rs)        \n",
    "        clf = Pipeline([('scaler', StandardScaler()), ('lr', LogisticRegression())])\n",
    "        # during training, we oversample to maximize utilization of the available\n",
    "        #  samples but learn a balanced dataset\n",
    "        rus = RandomOverSampler(random_state=rs)\n",
    "        X_train_resamp, y_train_resamp = rus.fit_resample(X_train, y_train)\n",
    "        clf.fit(X_train_resamp, y_train_resamp)\n",
    "        # during testing, we undersample such that we have a 50/50 prior\n",
    "        #  because the actual distribution is not balanced and skewed to i.e. PTLD & Acute Lyme\n",
    "        rus = RandomUnderSampler(random_state=rs)\n",
    "        X_test_resamp, y_test_resamp = rus.fit_resample(X_test, y_test)\n",
    "\n",
    "        # we capture these values for per-feature analysis\n",
    "        fpr_train, tpr_train, _ = roc_curve(clf.predict(X_train_resamp), y_train_resamp)\n",
    "        roc_score_train = auc(fpr_train, tpr_train)\n",
    "        prec_train, rec_train, _ = precision_recall_curve(clf.predict(X_train_resamp), y_train_resamp)\n",
    "        pr_score_train = average_precision_score(clf.predict(X_train_resamp), y_train_resamp)\n",
    "        confusion_train = confusion_matrix(clf.predict(X_train_resamp), y_train_resamp)\n",
    "        \n",
    "        fpr_test, tpr_test, _ = roc_curve(clf.predict(X_test_resamp), y_test_resamp)\n",
    "        roc_score_test = auc(fpr_test, tpr_test)\n",
    "        prec_test, rec_test, _ = precision_recall_curve(clf.predict(X_test_resamp), y_test_resamp)\n",
    "        pr_score_test = average_precision_score(clf.predict(X_test_resamp), y_test_resamp)\n",
    "        confusion_test = confusion_matrix(clf.predict(X_test_resamp), y_test_resamp)\n",
    "\n",
    "        results.append(dict(\n",
    "            label=label, gene=g,\n",
    "            train=dict(\n",
    "                confusion=confusion_train,\n",
    "                roc=dict(fpr=fpr_train, tpr=tpr_train, auc=roc_score_train),\n",
    "                pr=dict(prec=fpr_train, rec=tpr_train, auc=pr_score_train),\n",
    "            ),\n",
    "            test=dict(\n",
    "                confusion=confusion_test,\n",
    "                roc=dict(fpr=fpr_test, tpr=tpr_test, auc=roc_score_test),\n",
    "                pr=dict(prec=prec_test, rec=rec_test, auc=pr_score_test),\n",
    "            )\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39150e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame([\n",
    "    dict(label=r['label'], gene=r['gene'], kind=kind, auc=r[kind]['roc']['auc'])\n",
    "    for i, r in enumerate(results)\n",
    "    for kind in ['train', 'test']\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb7170b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(16, 6))\n",
    "sns.violinplot(data=df_results, x='gene',y='auc', hue='kind')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66246d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(df_results[(df_results['kind']=='test')].pivot('gene', 'label', 'auc'))\n",
    "plt.savefig(figures/'fig7.svg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
